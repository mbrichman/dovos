import requests
import pandas as pd
from datetime import datetime
from tabulate import tabulate

# GitHub API Token (Ensure it has correct permissions)
GITHUB_TOKEN = "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"

# GitHub Owner (Organization or User)
OWNER = "iman-dev"  # Example: "microsoft"

# Base GitHub API URL
BASE_API_URL = f"https://api.github.com/orgs/{OWNER}/repos"

# Headers for API Authentication
HEADERS = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

def get_repos():
    """Fetches all repositories under the owner"""
    response = requests.get(BASE_API_URL, headers=HEADERS)
    
    if response.status_code != 200:
        print(f"Error: Unable to fetch repositories (Status Code: {response.status_code})")
        print(response.json())
        return []

    repos = response.json()
    return [repo["name"] for repo in repos]  # Extract repo names

def get_merged_prs(repo):
    """Fetches merged pull requests for a specific repository"""
    api_url = f"https://api.github.com/repos/{OWNER}/{repo}/pulls"
    params = {
        "state": "closed",  # Fetch closed PRs (including merged ones)
        "per_page": 100
    }

    response = requests.get(api_url, headers=HEADERS, params=params)

    if response.status_code != 200:
        print(f"Error: Unable to fetch PRs for {repo} (Status Code: {response.status_code})")
        print(response.json())
        return []

    pr_data = response.json()
    merged_prs = []

    for pr in pr_data:
        if pr.get("merged_at"):  # Only include merged PRs
            merged_prs.append({
                "Repo Name": repo,
                "PR Number": pr["number"],
                "Title": pr["title"],
                "Created At": pr["created_at"],
                "Merged At": pr["merged_at"],
                "Initiator": pr["user"]["login"],  # PR Author
                "Approvers": get_pr_approvers(repo, pr["number"])  # Get approvers
            })

    return merged_prs

def get_pr_approvers(repo, pr_number):
    """Fetches approvers (reviewers who approved) for a given PR in a specific repository"""
    reviews_url = f"https://api.github.com/repos/{OWNER}/{repo}/pulls/{pr_number}/reviews"
    response = requests.get(reviews_url, headers=HEADERS)

    if response.status_code != 200:
        print(f"Warning: Unable to fetch reviewers for PR {pr_number} in {repo}.")
        return "Unknown"

    reviews = response.json()
    approvers = {review["user"]["login"] for review in reviews if review["state"] == "APPROVED"}

    return ", ".join(approvers) if approvers else "No Approvers"

def calculate_merge_time(prs):
    """Calculates the time taken to merge each PR"""
    for pr in prs:
        created_at = datetime.strptime(pr["Created At"], "%Y-%m-%dT%H:%M:%SZ")
        merged_at = datetime.strptime(pr["Merged At"], "%Y-%m-%dT%H:%M:%SZ")
        pr["Time to Merge"] = merged_at - created_at  # Time Difference

    return prs

def summarize_merge_times(prs):
    """Calculates and prints the average time to merge PRs"""
    if not prs:
        return None

    total_time = sum((pr["Time to Merge"] for pr in prs), datetime.min - datetime.min)
    avg_time = total_time / len(prs)

    summary = {
        "Total PRs Merged": len(prs),
        "Average Time to Merge": str(avg_time)
    }

    return summary

def save_to_csv(prs, summary):
    """Saves the summary and all PR data into a single CSV file"""
    filename = f"{OWNER}_all_repos_merged_prs.csv"

    # Convert PR Data to DataFrame
    df_prs = pd.DataFrame(prs)
    df_prs["Time to Merge"] = df_prs["Time to Merge"].astype(str)  # Convert timedelta to string

    # Sort by Created At
    df_prs["Created At"] = pd.to_datetime(df_prs["Created At"])
    df_prs.sort_values(by="Created At", ascending=True, inplace=True)

    # Convert Summary Data to DataFrame
    df_summary = pd.DataFrame(summary.items(), columns=["Metric", "Value"])

    # Write both dataframes to CSV (summary first, then PR data)
    with open(filename, "w", newline="") as f:
        df_summary.to_csv(f, index=False)
        f.write("\n")  # Add a blank line between summary and data
        df_prs.to_csv(f, index=False)

    print(f"âœ… Data saved to {filename}")

def display_pr_data(prs):
    """Displays PR merge data in a table format"""
    df = pd.DataFrame(prs)
    df["Time to Merge"] = df["Time to Merge"].astype(str)  # Convert timedelta to string
    df["Created At"] = pd.to_datetime(df["Created At"])
    df.sort_values(by="Created At", ascending=True, inplace=True)

    print("\n=== All Merged PRs Across Repositories ===")
    #print(tabulate(df, headers="keys", tablefmt="pretty"))

def main():
    print(f"Fetching repositories under '{OWNER}'...\n")
    repos = get_repos()

    if not repos:
        print("No repositories found.")
        return

    all_prs = []

    for repo in repos:
        print(f"\nProcessing repository: {repo}\n")
        
        merged_prs = get_merged_prs(repo)

        if not merged_prs:
            print(f"No merged PRs found for {repo}. Skipping...\n")
            continue

        merged_prs = calculate_merge_time(merged_prs)
        all_prs.extend(merged_prs)

    if not all_prs:
        print("No merged PRs found across all repositories.")
        return

    display_pr_data(all_prs)
    summary = summarize_merge_times(all_prs)
    
    if summary:
        save_to_csv(all_prs, summary)

if __name__ == "__main__":
    main()
